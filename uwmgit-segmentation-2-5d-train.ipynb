{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e3c0de",
   "metadata": {
    "papermill": {
     "duration": 0.011112,
     "end_time": "2023-04-21T20:16:48.579967",
     "exception": false,
     "start_time": "2023-04-21T20:16:48.568855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library Installation & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e743dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:16:48.603366Z",
     "iopub.status.busy": "2023-04-21T20:16:48.602436Z",
     "iopub.status.idle": "2023-04-21T20:16:48.612399Z",
     "shell.execute_reply": "2023-04-21T20:16:48.610980Z"
    },
    "papermill": {
     "duration": 0.027393,
     "end_time": "2023-04-21T20:16:48.616977",
     "exception": false,
     "start_time": "2023-04-21T20:16:48.589584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31380607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:16:48.658083Z",
     "iopub.status.busy": "2023-04-21T20:16:48.657413Z",
     "iopub.status.idle": "2023-04-21T20:17:36.127866Z",
     "shell.execute_reply": "2023-04-21T20:17:36.126794Z"
    },
    "papermill": {
     "duration": 47.481982,
     "end_time": "2023-04-21T20:17:36.130246",
     "exception": false,
     "start_time": "2023-04-21T20:16:48.648264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/segmentation-models-pytorch-021/wheels/pretrainedmodels-0.7.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (0.12.0)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (2.5.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (4.64.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (1.11.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (4.2.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (9.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (1.21.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (2.27.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (2022.5.18.1)\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (4.2.0)\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/timm-0.4.12-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (1.11.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (0.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12) (4.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (2.27.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (9.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (1.21.6)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (1.26.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (2.0.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (2022.5.18.1)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.12\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/segmentation_models_pytorch-0.2.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.12.0)\r\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.7.4)\r\n",
      "Requirement already satisfied: timm==0.4.12 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.4.12)\r\n",
      "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.6.3)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (1.11.0)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (2.5.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (4.64.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.27.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (9.1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (4.2.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (1.16.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2022.5.18.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.26.9)\r\n",
      "Installing collected packages: segmentation-models-pytorch\r\n",
      "Successfully installed segmentation-models-pytorch-0.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/monai-wheel/monai-0.9.0-202206131636-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from monai==0.9.0) (1.11.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai==0.9.0) (1.21.6)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->monai==0.9.0) (4.2.0)\r\n",
      "Installing collected packages: monai\r\n",
      "Successfully installed monai-0.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/pretrainedmodels-0.7.4-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/timm-0.4.12-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/segmentation_models_pytorch-0.2.1-py3-none-any.whl\"\n",
    "!pip install \"../input/monai-wheel/monai-0.9.0-202206131636-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc972e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:36.152070Z",
     "iopub.status.busy": "2023-04-21T20:17:36.151597Z",
     "iopub.status.idle": "2023-04-21T20:17:47.295050Z",
     "shell.execute_reply": "2023-04-21T20:17:47.294161Z"
    },
    "papermill": {
     "duration": 11.157187,
     "end_time": "2023-04-21T20:17:47.297507",
     "exception": false,
     "start_time": "2023-04-21T20:17:36.140320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "import json\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,StratifiedGroupKFold\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "#monai\n",
    "from monai.metrics.utils import get_mask_edges, get_surface_distance\n",
    "from monai.networks.nets import SwinUNETR\n",
    "import monai\n",
    "#keras\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d1756",
   "metadata": {
    "papermill": {
     "duration": 0.009417,
     "end_time": "2023-04-21T20:17:47.317041",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.307624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f2d969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:47.338095Z",
     "iopub.status.busy": "2023-04-21T20:17:47.337442Z",
     "iopub.status.idle": "2023-04-21T20:17:47.344195Z",
     "shell.execute_reply": "2023-04-21T20:17:47.343215Z"
    },
    "papermill": {
     "duration": 0.01965,
     "end_time": "2023-04-21T20:17:47.346329",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.326679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    exp_name      = 'v4'\n",
    "    comment       = 'unet-efficientnet_b0-320x384'\n",
    "    model_name    = 'UnetPlusPlus'\n",
    "    backbone      = 'efficientnet-b0'\n",
    "    train_bs      = 32\n",
    "    valid_bs      = train_bs*2\n",
    "    img_size      = 320\n",
    "    epochs        = 15\n",
    "    lr            = 2e-3\n",
    "    num_slices    = 5\n",
    "    in_channels   = 3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 9\n",
    "    folds         = [0]\n",
    "    num_classes   = 3\n",
    "    thr           = 0.40\n",
    "#     device        = torch.device(\"cpu\")\n",
    "    device        = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b587b19",
   "metadata": {
    "papermill": {
     "duration": 0.009407,
     "end_time": "2023-04-21T20:17:47.365484",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.356077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9828655d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:47.385930Z",
     "iopub.status.busy": "2023-04-21T20:17:47.385585Z",
     "iopub.status.idle": "2023-04-21T20:17:47.397227Z",
     "shell.execute_reply": "2023-04-21T20:17:47.396023Z"
    },
    "papermill": {
     "duration": 0.023917,
     "end_time": "2023-04-21T20:17:47.398998",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.375081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    #When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #Set a fixed value for the hash seed\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce194a",
   "metadata": {
    "papermill": {
     "duration": 0.009596,
     "end_time": "2023-04-21T20:17:47.418191",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.408595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d642b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:47.438399Z",
     "iopub.status.busy": "2023-04-21T20:17:47.438124Z",
     "iopub.status.idle": "2023-04-21T20:17:47.442042Z",
     "shell.execute_reply": "2023-04-21T20:17:47.441169Z"
    },
    "papermill": {
     "duration": 0.01613,
     "end_time": "2023-04-21T20:17:47.443933",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.427803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = \"../input/uw-madison-gi-tract-image-segmentation/train/case101/case101_day20/scans/slice_0001_266_266_1.50_1.50.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be47a2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:47.464115Z",
     "iopub.status.busy": "2023-04-21T20:17:47.463855Z",
     "iopub.status.idle": "2023-04-21T20:17:48.055811Z",
     "shell.execute_reply": "2023-04-21T20:17:48.054996Z"
    },
    "papermill": {
     "duration": 0.60447,
     "end_time": "2023-04-21T20:17:48.057924",
     "exception": false,
     "start_time": "2023-04-21T20:17:47.453454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4b0af1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:48.079867Z",
     "iopub.status.busy": "2023-04-21T20:17:48.079132Z",
     "iopub.status.idle": "2023-04-21T20:17:48.097506Z",
     "shell.execute_reply": "2023-04-21T20:17:48.096822Z"
    },
    "papermill": {
     "duration": 0.031166,
     "end_time": "2023-04-21T20:17:48.099291",
     "exception": false,
     "start_time": "2023-04-21T20:17:48.068125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class segmentation\n",
       "0  case123_day20_slice_0001  large_bowel          NaN\n",
       "1  case123_day20_slice_0001  small_bowel          NaN\n",
       "2  case123_day20_slice_0001      stomach          NaN\n",
       "3  case123_day20_slice_0002  large_bowel          NaN\n",
       "4  case123_day20_slice_0002  small_bowel          NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8096e58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:48.147052Z",
     "iopub.status.busy": "2023-04-21T20:17:48.146533Z",
     "iopub.status.idle": "2023-04-21T20:17:48.155936Z",
     "shell.execute_reply": "2023-04-21T20:17:48.155271Z"
    },
    "papermill": {
     "duration": 0.021433,
     "end_time": "2023-04-21T20:17:48.157634",
     "exception": false,
     "start_time": "2023-04-21T20:17:48.136201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    \n",
    "    ans=False\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            if np.isnan(row[\"segmentation\"][i]):\n",
    "                ans=False\n",
    "            else:\n",
    "                ans=True\n",
    "        except:\n",
    "            ans=True\n",
    "    row[\"empty\"] = ans\n",
    "    \n",
    "    return row\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e584de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:17:48.177800Z",
     "iopub.status.busy": "2023-04-21T20:17:48.177518Z",
     "iopub.status.idle": "2023-04-21T20:20:42.667450Z",
     "shell.execute_reply": "2023-04-21T20:20:42.666649Z"
    },
    "papermill": {
     "duration": 174.503571,
     "end_time": "2023-04-21T20:20:42.670824",
     "exception": false,
     "start_time": "2023-04-21T20:17:48.167253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id     segmentation\n",
      "0  case101_day20_slice_0001  [nan, nan, nan]\n",
      "1  case101_day20_slice_0002  [nan, nan, nan]\n",
      "2  case101_day20_slice_0003  [nan, nan, nan]\n",
      "3  case101_day20_slice_0004  [nan, nan, nan]\n",
      "4  case101_day20_slice_0005  [nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38496/38496 [01:16<00:00, 501.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id     segmentation  case  day  slice  empty\n",
      "0  case101_day20_slice_0001  [nan, nan, nan]   101   20      1  False\n",
      "1  case101_day20_slice_0002  [nan, nan, nan]   101   20      2  False\n",
      "2  case101_day20_slice_0003  [nan, nan, nan]   101   20      3  False\n",
      "3  case101_day20_slice_0004  [nan, nan, nan]   101   20      4  False\n",
      "4  case101_day20_slice_0005  [nan, nan, nan]   101   20      5  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38496/38496 [01:30<00:00, 425.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>empty</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case101_day20_slice_0001</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case101_day20_slice_0002</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case101_day20_slice_0003</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case101_day20_slice_0004</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case101_day20_slice_0005</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id     segmentation  case  day  slice  empty  \\\n",
       "0  case101_day20_slice_0001  [nan, nan, nan]   101   20      1  False   \n",
       "1  case101_day20_slice_0002  [nan, nan, nan]   101   20      2  False   \n",
       "2  case101_day20_slice_0003  [nan, nan, nan]   101   20      3  False   \n",
       "3  case101_day20_slice_0004  [nan, nan, nan]   101   20      4  False   \n",
       "4  case101_day20_slice_0005  [nan, nan, nan]   101   20      5  False   \n",
       "\n",
       "                                          image_path  height  width  \n",
       "0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "3  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "4  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby(['id'])['segmentation'].agg(list).to_frame().reset_index()\n",
    "print(df.head())\n",
    "order=[\"large_bowel\",\"small_bowel\",\"stomach\"]\n",
    "\n",
    "df = df.progress_apply(get_metadata, axis=1)\n",
    "print(df.head())\n",
    "\n",
    "paths = glob('/kaggle/input/uw-madison-gi-tract-image-segmentation/train/*/*/*/*')\n",
    "path_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "path_df = path_df.progress_apply(path2info, axis=1)\n",
    "df = df.merge(path_df, on=['case','day','slice'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ba455",
   "metadata": {
    "papermill": {
     "duration": 0.086596,
     "end_time": "2023-04-21T20:20:43.028834",
     "exception": false,
     "start_time": "2023-04-21T20:20:42.942238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5458fc81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:43.201681Z",
     "iopub.status.busy": "2023-04-21T20:20:43.201313Z",
     "iopub.status.idle": "2023-04-21T20:20:43.219876Z",
     "shell.execute_reply": "2023-04-21T20:20:43.219149Z"
    },
    "papermill": {
     "duration": 0.107298,
     "end_time": "2023-04-21T20:20:43.221900",
     "exception": false,
     "start_time": "2023-04-21T20:20:43.114602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def rle_encode(mask_img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "#     pixels = img.ravel(order='F')\n",
    "#     print(type(mask_img))\n",
    "    pixels = mask_img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    mask_rle = ' '.join(str(x) for x in runs)\n",
    "    return mask_rle\n",
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img\n",
    "def load_slice(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    img = cv2.resize(img,(CFG.img_size, CFG.img_size),interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "def load_5c_img(df, id):\n",
    "    img = np.zeros((CFG.img_size, CFG.img_size, CFG.in_channels),dtype = np.float32)\n",
    "    for i, diff in enumerate(range(-(CFG.num_slices//2), CFG.num_slices//2 +1,2)):\n",
    "        tmp = id.split(\"_\")\n",
    "        tmp[3] = str(int(tmp[3])+diff).zfill(4)\n",
    "        id_tmp=\"_\".join(tmp)\n",
    "        if df[\"id\"].isin([id_tmp]).any().any():\n",
    "            img[:,:,i] = load_slice(str(df[df[\"id\"]==id_tmp][\"image_path\"].squeeze()))\n",
    "        else:\n",
    "            img[:,:,i] = load_slice(str(df[df[\"id\"]==id][\"image_path\"].squeeze()))\n",
    "    max_val = img.max()\n",
    "    if max_val != 0 :\n",
    "        img /= max_val\n",
    "    return img\n",
    "def load_slice_other(img_file, diff):\n",
    "    slice_num = os.path.basename(img_file).split('_')[1]\n",
    "    filename = (\n",
    "        img_file.replace(\n",
    "            'slice_' + slice_num,\n",
    "            'slice_' + str(int(slice_num) + diff).zfill(4)))\n",
    "    if os.path.exists(filename):\n",
    "        return cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    return cv2.imread(img_file, cv2.IMREAD_UNCHANGED)\n",
    "def load_5c_img_other(img_file):\n",
    "    imgs = [load_slice_other(img_file, i) for i in range(-2, 3,2)]\n",
    "    img = np.stack(imgs, axis=2)\n",
    "    img = img.astype(np.float32)\n",
    "#     img = cv2.resize(img,(CFG.img_size, CFG.img_size),interpolation = cv2.INTER_AREA)\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf2d5692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:43.394544Z",
     "iopub.status.busy": "2023-04-21T20:20:43.394179Z",
     "iopub.status.idle": "2023-04-21T20:20:43.407806Z",
     "shell.execute_reply": "2023-04-21T20:20:43.406926Z"
    },
    "papermill": {
     "duration": 0.102346,
     "end_time": "2023-04-21T20:20:43.409674",
     "exception": false,
     "start_time": "2023-04-21T20:20:43.307328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/case101/case101_day20/scans/slice_0070_266_266_1.50_1.50.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id=\"case101_day20_slice_0070\"\n",
    "path = df[df[\"id\"]==id][\"image_path\"].squeeze()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f58c31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:43.814468Z",
     "iopub.status.busy": "2023-04-21T20:20:43.813662Z",
     "iopub.status.idle": "2023-04-21T20:20:43.837242Z",
     "shell.execute_reply": "2023-04-21T20:20:43.835803Z"
    },
    "papermill": {
     "duration": 0.112034,
     "end_time": "2023-04-21T20:20:43.839097",
     "exception": false,
     "start_time": "2023-04-21T20:20:43.727063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38496 entries, 0 to 38495\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            38496 non-null  object\n",
      " 1   segmentation  38496 non-null  object\n",
      " 2   case          38496 non-null  int64 \n",
      " 3   day           38496 non-null  int64 \n",
      " 4   slice         38496 non-null  int64 \n",
      " 5   empty         38496 non-null  bool  \n",
      " 6   image_path    38496 non-null  object\n",
      " 7   height        38496 non-null  int64 \n",
      " 8   width         38496 non-null  int64 \n",
      "dtypes: bool(1), int64(5), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e29e52",
   "metadata": {
    "papermill": {
     "duration": 0.086417,
     "end_time": "2023-04-21T20:20:44.012262",
     "exception": false,
     "start_time": "2023-04-21T20:20:43.925845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mask creation + dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7429d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:44.363336Z",
     "iopub.status.busy": "2023-04-21T20:20:44.362988Z",
     "iopub.status.idle": "2023-04-21T20:20:44.380726Z",
     "shell.execute_reply": "2023-04-21T20:20:44.379824Z"
    },
    "papermill": {
     "duration": 0.106502,
     "end_time": "2023-04-21T20:20:44.382930",
     "exception": false,
     "start_time": "2023-04-21T20:20:44.276428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "def id2mask(id_):\n",
    "    idf = df[df['id']==id_]\n",
    "    shape = (df[df['id']==id_][\"height\"].squeeze(), idf[\"width\"].squeeze(), 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, rle in enumerate(idf[\"segmentation\"].squeeze()):\n",
    "        if pd.notnull(rle):\n",
    "            mask[:,:, i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "print(np.unique(id2mask(\"case123_day20_slice_0068\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1adb3c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:44.556307Z",
     "iopub.status.busy": "2023-04-21T20:20:44.555485Z",
     "iopub.status.idle": "2023-04-21T20:20:44.564519Z",
     "shell.execute_reply": "2023-04-21T20:20:44.563691Z"
    },
    "papermill": {
     "duration": 0.097363,
     "end_time": "2023-04-21T20:20:44.566373",
     "exception": false,
     "start_time": "2023-04-21T20:20:44.469010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        \"train\": A.Compose([\n",
    "                    A.Resize(CFG.img_size,CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "            ], p=0.25),\n",
    "            A.CoarseDropout(max_holes=8, max_height=CFG.img_size // 20, max_width=CFG.img_size // 20,\n",
    "                            min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "\n",
    "        \"valid\": A.Compose([A.Resize(CFG.img_size, CFG.img_size, interpolation=cv2.INTER_NEAREST)], p=1.0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee00ab21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:44.743248Z",
     "iopub.status.busy": "2023-04-21T20:20:44.742415Z",
     "iopub.status.idle": "2023-04-21T20:20:44.751258Z",
     "shell.execute_reply": "2023-04-21T20:20:44.750417Z"
    },
    "papermill": {
     "duration": 0.101676,
     "end_time": "2023-04-21T20:20:44.753039",
     "exception": false,
     "start_time": "2023-04-21T20:20:44.651363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, phase, transforms=None):\n",
    "        self.df         = df\n",
    "        self.phase      = phase\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path  = self.df.iloc[index][\"image_path\"]\n",
    "        id = self.df.iloc[index][\"id\"]\n",
    "        img = load_5c_img_other(img_path)\n",
    "        if self.phase != \"test\": #eval or train\n",
    "            msk = id2mask(id)            \n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            msk = np.transpose(msk, (2, 0, 1)) # ig for keeping the channels at top\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img), id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f55b5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:44.925456Z",
     "iopub.status.busy": "2023-04-21T20:20:44.925074Z",
     "iopub.status.idle": "2023-04-21T20:20:45.081233Z",
     "shell.execute_reply": "2023-04-21T20:20:45.080450Z"
    },
    "papermill": {
     "duration": 0.244965,
     "end_time": "2023-04-21T20:20:45.083044",
     "exception": false,
     "start_time": "2023-04-21T20:20:44.838079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  empty\n",
       "0.0   False    2869\n",
       "      True      667\n",
       "1.0   False    3944\n",
       "      True     1128\n",
       "2.0   False    3701\n",
       "      True     1051\n",
       "3.0   False    3499\n",
       "      True      901\n",
       "4.0   False    3567\n",
       "      True     1153\n",
       "5.0   False    2483\n",
       "      True      685\n",
       "6.0   False    3480\n",
       "      True     1080\n",
       "7.0   False    3548\n",
       "      True     1060\n",
       "8.0   False    2778\n",
       "      True      902\n",
       "Name: id, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['empty'], groups = df[\"case\"])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','empty'])['id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "757db074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:45.260596Z",
     "iopub.status.busy": "2023-04-21T20:20:45.260224Z",
     "iopub.status.idle": "2023-04-21T20:20:45.281424Z",
     "shell.execute_reply": "2023-04-21T20:20:45.280665Z"
    },
    "papermill": {
     "duration": 0.111538,
     "end_time": "2023-04-21T20:20:45.283273",
     "exception": false,
     "start_time": "2023-04-21T20:20:45.171735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = BuildDataset(train_df,phase=\"train\", transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df,phase=\"valid\", transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs,num_workers=4, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs ,num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "train_loader, valid_loader = prepare_loaders(fold=0, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b9f23f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:45.457273Z",
     "iopub.status.busy": "2023-04-21T20:20:45.456900Z",
     "iopub.status.idle": "2023-04-21T20:20:59.521458Z",
     "shell.execute_reply": "2023-04-21T20:20:59.520361Z"
    },
    "papermill": {
     "duration": 14.153869,
     "end_time": "2023-04-21T20:20:59.523537",
     "exception": false,
     "start_time": "2023-04-21T20:20:45.369668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 320, 320]), torch.Size([32, 3, 320, 320]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, msks = next(iter(train_loader))\n",
    "imgs.size(), msks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4cc9b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:20:59.698317Z",
     "iopub.status.busy": "2023-04-21T20:20:59.697936Z",
     "iopub.status.idle": "2023-04-21T20:21:00.894520Z",
     "shell.execute_reply": "2023-04-21T20:21:00.893708Z"
    },
    "papermill": {
     "duration": 1.286616,
     "end_time": "2023-04-21T20:21:00.896619",
     "exception": false,
     "start_time": "2023-04-21T20:20:59.610003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp \n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(\n",
    "        encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "        decoder_attention_type='scse',\n",
    "    )\n",
    "    \n",
    "#     model = monai.networks.nets.SwinUNETR(img_size=(CFG.img_size,CFG.img_size), in_channels=CFG.num_slices, out_channels=3, use_checkpoint=True, spatial_dims=2)\n",
    "#     takes too much time\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e278ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:01.070223Z",
     "iopub.status.busy": "2023-04-21T20:21:01.069847Z",
     "iopub.status.idle": "2023-04-21T20:21:01.083290Z",
     "shell.execute_reply": "2023-04-21T20:21:01.082754Z"
    },
    "papermill": {
     "duration": 0.101777,
     "end_time": "2023-04-21T20:21:01.084855",
     "exception": false,
     "start_time": "2023-04-21T20:21:00.983078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel')\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.5*BCELoss(y_pred, y_true) + 0.5*DiceLoss(y_pred, y_true)\n",
    "\n",
    "def compute_hausdorff_monai(pred, gt):\n",
    "    pred=np.array(pred)\n",
    "    gt=np.array(gt)\n",
    "    max_dist = np.sqrt((pred.shape[0]**2)+(pred.shape[1]**2)+(pred.shape[2]**2))\n",
    "    \n",
    "    if np.all(pred == gt):\n",
    "        return 0.0\n",
    "    (edges_pred, edges_gt) = get_mask_edges(pred, gt)\n",
    "    surface_distance = get_surface_distance(edges_pred, edges_gt, distance_metric=\"euclidean\")\n",
    "    if surface_distance.shape == (0,):\n",
    "        return 0.0\n",
    "    dist = surface_distance.max()\n",
    "    if dist > max_dist:\n",
    "        return 1.0\n",
    "    return dist / max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9e868b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:01.258490Z",
     "iopub.status.busy": "2023-04-21T20:21:01.258121Z",
     "iopub.status.idle": "2023-04-21T20:21:01.327661Z",
     "shell.execute_reply": "2023-04-21T20:21:01.326804Z"
    },
    "papermill": {
     "duration": 0.1591,
     "end_time": "2023-04-21T20:21:01.329497",
     "exception": false,
     "start_time": "2023-04-21T20:21:01.170397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for random pred and label: \n",
      "0.005524082076968276\n",
      "result for random pred and empty label: \n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "image_shape = (256, 256,3)\n",
    "\n",
    "pred = np.random.randint(0, high=2, size=image_shape)\n",
    "label = np.random.randint(0, high=2, size=image_shape)\n",
    "print(\"result for random pred and label: \")\n",
    "print(compute_hausdorff_monai(pred, label))\n",
    "print(\"result for random pred and empty label: \")\n",
    "label_empty = np.zeros(image_shape)\n",
    "print(compute_hausdorff_monai(pred, label_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deed6aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:01.544610Z",
     "iopub.status.busy": "2023-04-21T20:21:01.543752Z",
     "iopub.status.idle": "2023-04-21T20:21:01.552602Z",
     "shell.execute_reply": "2023-04-21T20:21:01.551841Z"
    },
    "papermill": {
     "duration": 0.096883,
     "end_time": "2023-04-21T20:21:01.554307",
     "exception": false,
     "start_time": "2023-04-21T20:21:01.457424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:         \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate\n",
    "#         train_dice = dice_coef(masks, y_pred)\n",
    "#         train_hausdorff  = compute_hausdorff_monai(y_pred, masks)\n",
    "#         train_mix = 0.4*train_dice + 0.6*train_haussdorf\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "    \n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1017e239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:01.728639Z",
     "iopub.status.busy": "2023-04-21T20:21:01.727814Z",
     "iopub.status.idle": "2023-04-21T20:21:01.736845Z",
     "shell.execute_reply": "2023-04-21T20:21:01.736049Z"
    },
    "papermill": {
     "duration": 0.098718,
     "end_time": "2023-04-21T20:21:01.738544",
     "exception": false,
     "start_time": "2023-04-21T20:21:01.639826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred)\n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_hausdorff  = compute_hausdorff_monai(y_pred.cpu(), masks.cpu())\n",
    "        val_mix = 0.4*val_dice + 0.6*val_hausdorff\n",
    "        val_scores.append([val_dice, val_jaccard, val_hausdorff, val_mix])\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',)\n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce14700d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:01.912102Z",
     "iopub.status.busy": "2023-04-21T20:21:01.911185Z",
     "iopub.status.idle": "2023-04-21T20:21:01.921916Z",
     "shell.execute_reply": "2023-04-21T20:21:01.921142Z"
    },
    "papermill": {
     "duration": 0.099623,
     "end_time": "2023-04-21T20:21:01.923742",
     "exception": false,
     "start_time": "2023-04-21T20:21:01.824119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "    epochs=[]\n",
    "    train_losses=[]\n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        epochs.append(epoch)\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        \n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        if epoch == num_epochs: \n",
    "            \n",
    "            \n",
    "            val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "            val_dice, val_jaccard, val_hausdorff, val_mix = val_scores\n",
    "\n",
    "#             history['Train Loss'].append(train_loss)\n",
    "            history['Valid Loss'].append(val_loss)\n",
    "            history['Valid Dice'].append(val_dice)\n",
    "            history['Valid Jaccard'].append(val_jaccard)\n",
    "\n",
    "            print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f} | val_hausdorff: {val_hausdorff:0.4f} | val_mix: {val_mix:0.4f}')\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(last_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fc81206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:02.097430Z",
     "iopub.status.busy": "2023-04-21T20:21:02.096447Z",
     "iopub.status.idle": "2023-04-21T20:21:02.103522Z",
     "shell.execute_reply": "2023-04-21T20:21:02.102823Z"
    },
    "papermill": {
     "duration": 0.095549,
     "end_time": "2023-04-21T20:21:02.105247",
     "exception": false,
     "start_time": "2023-04-21T20:21:02.009698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduler == 'ExponentialLR':#\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f9dd440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:02.278096Z",
     "iopub.status.busy": "2023-04-21T20:21:02.277229Z",
     "iopub.status.idle": "2023-04-21T20:21:02.753642Z",
     "shell.execute_reply": "2023-04-21T20:21:02.752824Z"
    },
    "papermill": {
     "duration": 0.565207,
     "end_time": "2023-04-21T20:21:02.755736",
     "exception": false,
     "start_time": "2023-04-21T20:21:02.190529",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecb52a8cf144cf4a1994a332a286107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/20.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "scheduler = fetch_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c8d6e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:21:02.930622Z",
     "iopub.status.busy": "2023-04-21T20:21:02.929824Z",
     "iopub.status.idle": "2023-04-22T02:02:14.198681Z",
     "shell.execute_reply": "2023-04-22T02:02:14.197642Z"
    },
    "papermill": {
     "duration": 20471.357321,
     "end_time": "2023-04-22T02:02:14.200617",
     "exception": false,
     "start_time": "2023-04-21T20:21:02.843296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n",
      "### Fold: 0\n",
      "###############\n",
      "cuda: Tesla P100-PCIE-16GB\n",
      "\n",
      "Epoch 1/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:53<00:00,  1.26s/it, lr=0.00197, train_loss=0.2284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:14<00:00,  1.22s/it, lr=0.00188, train_loss=0.1242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:18<00:00,  1.22s/it, lr=0.00175, train_loss=0.1093]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:46<00:00,  1.25s/it, lr=0.00156, train_loss=0.1024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:47<00:00,  1.25s/it, lr=0.00135, train_loss=0.0956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:53<00:00,  1.26s/it, lr=0.00111, train_loss=0.0900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:35<00:00,  1.24s/it, lr=0.00087, train_loss=0.0838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:53<00:00,  1.26s/it, lr=0.00063, train_loss=0.0800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:41<00:00,  1.25s/it, lr=0.00042, train_loss=0.0750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:53<00:00,  1.26s/it, lr=0.00024, train_loss=0.0714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:41<00:00,  1.25s/it, lr=0.00011, train_loss=0.0686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:28<00:00,  1.23s/it, lr=0.00003, train_loss=0.0667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:33<00:00,  1.24s/it, lr=0.00000, train_loss=0.0662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:28<00:00,  1.23s/it, lr=0.00004, train_loss=0.0661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train : 100%|██████████| 1093/1093 [22:35<00:00,  1.24s/it, lr=0.00013, train_loss=0.0657]\n",
      "Valid : 100%|██████████| 56/56 [01:18<00:00,  1.40s/it, lr=0.00013, valid_loss=0.0831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dice: 0.9201 | Valid Jaccard: 0.8969 | val_hausdorff: 0.8393 | val_mix: 0.8716\n",
      "Training complete in 5h 41m 11s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(1):\n",
    "    print(f'#'*15)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*15)\n",
    "\n",
    "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
    "    model     = build_model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history = run_training(model, optimizer, scheduler,\n",
    "                                  device=CFG.device,\n",
    "                                  num_epochs=CFG.epochs)\n",
    "    \n",
    "###loss vs epoch graph at last\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20757.464515,
   "end_time": "2023-04-22T02:02:38.285000",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-21T20:16:40.820485",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00e9740e6e67400980d9ac8c013d83c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "372033ff4f9d4cd4822ce2cb8cc35bdb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4718513e00d74e8a9b09b0dc8b466105": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "51d908634a6c4119bf413c8953bbbf7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_914035f8711847c2beff82f412e9e3e4",
       "placeholder": "​",
       "style": "IPY_MODEL_68d8dac56c9845ebb76e35b4d56d33cc",
       "value": " 20.4M/20.4M [00:00&lt;00:00, 124MB/s]"
      }
     },
     "68d8dac56c9845ebb76e35b4d56d33cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7ecb52a8cf144cf4a1994a332a286107": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ebb7d402878d451b8f78c124a5c20795",
        "IPY_MODEL_f3b8917ab84f43a0866287fbd4d525ee",
        "IPY_MODEL_51d908634a6c4119bf413c8953bbbf7c"
       ],
       "layout": "IPY_MODEL_eb6e7acdc4f44196bfbb7aa1ddad29d6"
      }
     },
     "8646191efdde449a83a847d3e6c005d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "914035f8711847c2beff82f412e9e3e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb6e7acdc4f44196bfbb7aa1ddad29d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebb7d402878d451b8f78c124a5c20795": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_372033ff4f9d4cd4822ce2cb8cc35bdb",
       "placeholder": "​",
       "style": "IPY_MODEL_4718513e00d74e8a9b09b0dc8b466105",
       "value": "100%"
      }
     },
     "f3b8917ab84f43a0866287fbd4d525ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_00e9740e6e67400980d9ac8c013d83c6",
       "max": 21388428,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8646191efdde449a83a847d3e6c005d4",
       "value": 21388428
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
