{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961db5c3",
   "metadata": {
    "papermill": {
     "duration": 0.083023,
     "end_time": "2022-07-11T10:19:35.576671",
     "exception": false,
     "start_time": "2022-07-11T10:19:35.493648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library Installation & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030a7fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:19:35.749944Z",
     "iopub.status.busy": "2022-07-11T10:19:35.747581Z",
     "iopub.status.idle": "2022-07-11T10:22:05.610119Z",
     "shell.execute_reply": "2022-07-11T10:22:05.609122Z"
    },
    "papermill": {
     "duration": 149.951422,
     "end_time": "2022-07-11T10:22:05.612190",
     "exception": false,
     "start_time": "2022-07-11T10:19:35.660768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/segmentation-models-pytorch-021/wheels/pretrainedmodels-0.7.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (4.64.0)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (1.11.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (0.12.0)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4) (2.5.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels==0.7.4) (4.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (2.27.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (9.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels==0.7.4) (1.21.6)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->pretrainedmodels==0.7.4) (2022.5.18.1)\r\n",
      "Installing collected packages: pretrainedmodels\r\n",
      "Successfully installed pretrainedmodels-0.7.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3) (4.2.0)\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.6.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/timm-0.4.12-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (1.11.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.12) (0.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.12) (4.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (2.27.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.12) (9.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (2022.5.18.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.12) (2.0.12)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.12\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/segmentation-models-pytorch-021/wheels/segmentation_models_pytorch-0.2.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.7.4)\r\n",
      "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.6.3)\r\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.12.0)\r\n",
      "Requirement already satisfied: timm==0.4.12 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.4.12)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (1.11.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (4.64.0)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (2.5.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (9.1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (4.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.21.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.27.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.26.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2022.5.18.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (2.0.12)\r\n",
      "Installing collected packages: segmentation-models-pytorch\r\n",
      "Successfully installed segmentation-models-pytorch-0.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing /kaggle/input/monai-wheel/monai-0.8.1-202202162213-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from monai==0.8.1) (1.21.6)\r\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.7/site-packages (from monai==0.8.1) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->monai==0.8.1) (4.2.0)\r\n",
      "Installing collected packages: monai\r\n",
      "Successfully installed monai-0.8.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/pretrainedmodels-0.7.4-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/timm-0.4.12-py3-none-any.whl\"\n",
    "!pip install \"../input/segmentation-models-pytorch-021/wheels/segmentation_models_pytorch-0.2.1-py3-none-any.whl\"\n",
    "!pip install \"../input/monai-wheel/monai-0.8.1-202202162213-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0e706d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:05.768590Z",
     "iopub.status.busy": "2022-07-11T10:22:05.767986Z",
     "iopub.status.idle": "2022-07-11T10:22:19.040435Z",
     "shell.execute_reply": "2022-07-11T10:22:19.039420Z"
    },
    "papermill": {
     "duration": 13.351818,
     "end_time": "2022-07-11T10:22:19.042803",
     "exception": false,
     "start_time": "2022-07-11T10:22:05.690985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "import json\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,StratifiedGroupKFold\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import timm\n",
    "\n",
    "#monai\n",
    "from monai.metrics.utils import get_mask_edges, get_surface_distance\n",
    "\n",
    "#keras\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776da92",
   "metadata": {
    "papermill": {
     "duration": 0.082905,
     "end_time": "2022-07-11T10:22:19.211424",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.128519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6b545d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:19.386265Z",
     "iopub.status.busy": "2022-07-11T10:22:19.385011Z",
     "iopub.status.idle": "2022-07-11T10:22:19.394916Z",
     "shell.execute_reply": "2022-07-11T10:22:19.394099Z"
    },
    "papermill": {
     "duration": 0.099881,
     "end_time": "2022-07-11T10:22:19.397021",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.297140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    exp_name      = 'v4'\n",
    "    comment       = 'unet-efficientnet_b0-320x384'\n",
    "    model_name    = 'Unet'\n",
    "#     backbone      = 'timm-mobilenetv3_small_minimal_100'\n",
    "    backbone      = 'efficientnet-b0'\n",
    "    train_bs      = 32\n",
    "    valid_bs      = train_bs*2\n",
    "    img_size      = 320\n",
    "    epochs        = 1\n",
    "    lr            = 2e-3\n",
    "    num_slices    = 5\n",
    "    in_channels   = 3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 7\n",
    "    folds         = [0]\n",
    "    num_classes   = 3\n",
    "    thr           = 0.40\n",
    "#     device        = torch.device(\"cpu\")\n",
    "    device        = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d08236",
   "metadata": {
    "papermill": {
     "duration": 0.083867,
     "end_time": "2022-07-11T10:22:19.564883",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.481016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca40533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:19.735710Z",
     "iopub.status.busy": "2022-07-11T10:22:19.734659Z",
     "iopub.status.idle": "2022-07-11T10:22:19.746953Z",
     "shell.execute_reply": "2022-07-11T10:22:19.745704Z"
    },
    "papermill": {
     "duration": 0.100156,
     "end_time": "2022-07-11T10:22:19.748894",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.648738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "#     When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "#     Set a fixed value for the hash seed\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f949d",
   "metadata": {
    "papermill": {
     "duration": 0.083892,
     "end_time": "2022-07-11T10:22:19.914224",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.830332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ccec08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:20.083329Z",
     "iopub.status.busy": "2022-07-11T10:22:20.082708Z",
     "iopub.status.idle": "2022-07-11T10:22:20.103716Z",
     "shell.execute_reply": "2022-07-11T10:22:20.102548Z"
    },
    "papermill": {
     "duration": 0.109543,
     "end_time": "2022-07-11T10:22:20.106045",
     "exception": false,
     "start_time": "2022-07-11T10:22:19.996502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "def rle_encode(mask_img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "#     pixels = img.ravel(order='F')\n",
    "#     print(type(mask_img))\n",
    "    pixels = mask_img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    mask_rle = ' '.join(str(x) for x in runs)\n",
    "    return mask_rle\n",
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img\n",
    "def load_slice(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    #img = cv2.resize(img,(CFG.img_size, CFG.img_size),interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "def load_5c_img(df, id):\n",
    "    img = np.zeros((CFG.img_size, CFG.img_size, CFG.in_channels),dtype = np.float32)\n",
    "    for i, diff in enumerate(range(-(CFG.num_slices//2), CFG.num_slices//2 +1,2)):\n",
    "        tmp = id.split(\"_\")\n",
    "        tmp[3] = str(int(tmp[3])+diff).zfill(4)\n",
    "        id_tmp=\"_\".join(tmp)\n",
    "        if df[\"id\"].isin([id_tmp]).any().any():\n",
    "            img[:,:,i] = load_slice(str(df[df[\"id\"]==id_tmp][\"image_path\"].squeeze()))\n",
    "        else:\n",
    "            img[:,:,i] = load_slice(str(df[df[\"id\"]==id][\"image_path\"].squeeze()))\n",
    "    max_val = img.max()\n",
    "    if max_val != 0 :\n",
    "        img /= max_val\n",
    "    return img\n",
    "def load_slice_other(img_file, diff):\n",
    "    slice_num = os.path.basename(img_file).split('_')[1]\n",
    "    filename = (\n",
    "        img_file.replace(\n",
    "            'slice_' + slice_num,\n",
    "            'slice_' + str(int(slice_num) + diff).zfill(4)))\n",
    "    if os.path.exists(filename):\n",
    "        return cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    return cv2.imread(img_file, cv2.IMREAD_UNCHANGED)\n",
    "def load_5c_img_other(img_file):\n",
    "    imgs = [load_slice_other(img_file, i) for i in range(-2, 3,2)]\n",
    "    img = np.stack(imgs, axis=2)\n",
    "    img = img.astype(np.float32)\n",
    "    mx = np.max(img)\n",
    "    if mx:\n",
    "        img/=mx # scale image to [0, 1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8041e",
   "metadata": {
    "papermill": {
     "duration": 0.08175,
     "end_time": "2022-07-11T10:22:20.268136",
     "exception": false,
     "start_time": "2022-07-11T10:22:20.186386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268c4aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:20.420789Z",
     "iopub.status.busy": "2022-07-11T10:22:20.420388Z",
     "iopub.status.idle": "2022-07-11T10:22:20.430517Z",
     "shell.execute_reply": "2022-07-11T10:22:20.429724Z"
    },
    "papermill": {
     "duration": 0.089739,
     "end_time": "2022-07-11T10:22:20.432333",
     "exception": false,
     "start_time": "2022-07-11T10:22:20.342594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "#     row['id'] = f'case{case}_day{day}_slice_{slice_}'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd53cf3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:20.580644Z",
     "iopub.status.busy": "2022-07-11T10:22:20.579950Z",
     "iopub.status.idle": "2022-07-11T10:22:22.707450Z",
     "shell.execute_reply": "2022-07-11T10:22:22.706536Z"
    },
    "papermill": {
     "duration": 2.206105,
     "end_time": "2022-07-11T10:22:22.711044",
     "exception": false,
     "start_time": "2022-07-11T10:22:20.504939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 621.79it/s]\n"
     ]
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n",
    "if not len(sub_df):#during local save version this will activate\n",
    "    debug = True\n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n",
    "    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()\n",
    "else:#during submission this runs\n",
    "    debug = False\n",
    "    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\n",
    "sub_df = sub_df.progress_apply(get_metadata,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c18c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:22:22.883379Z",
     "iopub.status.busy": "2022-07-11T10:22:22.882897Z",
     "iopub.status.idle": "2022-07-11T10:23:53.714551Z",
     "shell.execute_reply": "2022-07-11T10:23:53.713801Z"
    },
    "papermill": {
     "duration": 91.062255,
     "end_time": "2022-07-11T10:23:53.858546",
     "exception": false,
     "start_time": "2022-07-11T10:22:22.796291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38496/38496 [01:30<00:00, 427.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  height  width  case  \\\n",
       "0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n",
       "1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n",
       "2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n",
       "3  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n",
       "4  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266    36   \n",
       "\n",
       "   day  slice  \n",
       "0   14      6  \n",
       "1   14     82  \n",
       "2   14    113  \n",
       "3   14     76  \n",
       "4   14    125  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if debug:\n",
    "    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n",
    "#     paths = sorted(paths)\n",
    "else:\n",
    "    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n",
    "#     paths = sorted(paths)\n",
    "path_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "path_df = path_df.progress_apply(path2info, axis=1)\n",
    "path_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4cbefb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:54.128450Z",
     "iopub.status.busy": "2022-07-11T10:23:54.127951Z",
     "iopub.status.idle": "2022-07-11T10:23:54.156321Z",
     "shell.execute_reply": "2022-07-11T10:23:54.155415Z"
    },
    "papermill": {
     "duration": 0.163306,
     "end_time": "2022-07-11T10:23:54.158240",
     "exception": false,
     "start_time": "2022-07-11T10:23:53.994934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0003</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0004</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0005</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>/kaggle/input/uw-madison-gi-tract-image-segmen...</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  case  day  slice  \\\n",
       "0  case123_day20_slice_0001   123   20      1   \n",
       "1  case123_day20_slice_0002   123   20      2   \n",
       "2  case123_day20_slice_0003   123   20      3   \n",
       "3  case123_day20_slice_0004   123   20      4   \n",
       "4  case123_day20_slice_0005   123   20      5   \n",
       "\n",
       "                                          image_path  height  width  \n",
       "0  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "1  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "2  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "3  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  \n",
       "4  /kaggle/input/uw-madison-gi-tract-image-segmen...     266    266  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235738a",
   "metadata": {
    "papermill": {
     "duration": 0.127822,
     "end_time": "2022-07-11T10:23:54.414474",
     "exception": false,
     "start_time": "2022-07-11T10:23:54.286652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mask creation + dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0edf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:54.670619Z",
     "iopub.status.busy": "2022-07-11T10:23:54.670187Z",
     "iopub.status.idle": "2022-07-11T10:23:54.676704Z",
     "shell.execute_reply": "2022-07-11T10:23:54.675976Z"
    },
    "papermill": {
     "duration": 0.136806,
     "end_time": "2022-07-11T10:23:54.678374",
     "exception": false,
     "start_time": "2022-07-11T10:23:54.541568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id2mask(id_):\n",
    "    idf = df[df['id']==id_]\n",
    "    shape = (df[df['id']==id_][\"height\"].squeeze(), idf[\"width\"].squeeze(), 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, rle in enumerate(idf[\"segmentation\"].squeeze()):\n",
    "        if pd.notnull(rle):\n",
    "            mask[:,:, i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "# print(id2mask(\"case123_day20_slice_0066\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b00e4902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:54.937729Z",
     "iopub.status.busy": "2022-07-11T10:23:54.937385Z",
     "iopub.status.idle": "2022-07-11T10:23:54.945920Z",
     "shell.execute_reply": "2022-07-11T10:23:54.945198Z"
    },
    "papermill": {
     "duration": 0.142966,
     "end_time": "2022-07-11T10:23:54.947724",
     "exception": false,
     "start_time": "2022-07-11T10:23:54.804758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "        \"train\": A.Compose([\n",
    "                    A.Resize(CFG.img_size,CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
    "            ], p=0.25),\n",
    "            A.CoarseDropout(max_holes=8, max_height=CFG.img_size // 20, max_width=CFG.img_size // 20,\n",
    "                            min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
    "        ], p=1.0),\n",
    "\n",
    "        \"valid\": A.Compose([A.Resize(CFG.img_size, CFG.img_size, interpolation=cv2.INTER_NEAREST)], p=1.0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d10f666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:55.208011Z",
     "iopub.status.busy": "2022-07-11T10:23:55.207558Z",
     "iopub.status.idle": "2022-07-11T10:23:55.218838Z",
     "shell.execute_reply": "2022-07-11T10:23:55.218024Z"
    },
    "papermill": {
     "duration": 0.144912,
     "end_time": "2022-07-11T10:23:55.220733",
     "exception": false,
     "start_time": "2022-07-11T10:23:55.075821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, label=False, transforms=None):\n",
    "        self.df         = df\n",
    "        self.label      = label\n",
    "        self.img_paths  = df['image_path'].tolist()\n",
    "        self.ids        = df['id'].tolist()\n",
    "        if 'msk_path' in df.columns:\n",
    "            self.msk_paths  = df['mask_path'].tolist()\n",
    "        else:\n",
    "            self.msk_paths = None\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        id_       = self.ids[index]\n",
    "        img = []\n",
    "#         img = load_5c_img(self.df, id_)\n",
    "        img = load_5c_img_other(img_path)\n",
    "        h, w = img.shape[:2]\n",
    "        if self.label:\n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img  = data['image']\n",
    "                msk  = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            msk = np.transpose(msk, (2, 0, 1))\n",
    "            return torch.tensor(img), torch.tensor(msk)\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            return torch.tensor(img), id_, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0491881c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:55.478360Z",
     "iopub.status.busy": "2022-07-11T10:23:55.477888Z",
     "iopub.status.idle": "2022-07-11T10:23:55.484380Z",
     "shell.execute_reply": "2022-07-11T10:23:55.483658Z"
    },
    "papermill": {
     "duration": 0.137804,
     "end_time": "2022-07-11T10:23:55.486003",
     "exception": false,
     "start_time": "2022-07-11T10:23:55.348199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#         encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        encoder_weights= None,\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n",
    "        activation=None,\n",
    "        decoder_attention_type='scse',\n",
    "    )\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635f3cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:55.744221Z",
     "iopub.status.busy": "2022-07-11T10:23:55.743427Z",
     "iopub.status.idle": "2022-07-11T10:23:55.753394Z",
     "shell.execute_reply": "2022-07-11T10:23:55.752562Z"
    },
    "papermill": {
     "duration": 0.142504,
     "end_time": "2022-07-11T10:23:55.755244",
     "exception": false,
     "start_time": "2022-07-11T10:23:55.612740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cupy as cp\n",
    "\n",
    "def mask2rle(msk, thr=0.5):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    msk    = np.array(msk)\n",
    "    pixels = msk.flatten()\n",
    "    pad    = np.array([0])\n",
    "    pixels = np.concatenate([pad, pixels, pad])\n",
    "    runs   = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def masks2rles(msks, ids, heights, widths):\n",
    "    pred_strings = []; pred_ids = []; pred_classes = [];\n",
    "    for idx in range(msks.shape[0]):\n",
    "        height = heights[idx].item()\n",
    "        width = widths[idx].item()\n",
    "        msk = cv2.resize(msks[idx], \n",
    "                         dsize=(width, height), \n",
    "                         interpolation=cv2.INTER_NEAREST) # back to original shape\n",
    "        rle = [None]*3\n",
    "        for midx in [0, 1, 2]:\n",
    "            rle[midx] = mask2rle(msk[...,midx])\n",
    "        pred_strings.extend(rle)\n",
    "        pred_ids.extend([ids[idx]]*len(rle))\n",
    "        pred_classes.extend(['large_bowel', 'small_bowel', 'stomach'])\n",
    "    return pred_strings, pred_ids, pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "592ab53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:56.016659Z",
     "iopub.status.busy": "2022-07-11T10:23:56.016205Z",
     "iopub.status.idle": "2022-07-11T10:23:56.027342Z",
     "shell.execute_reply": "2022-07-11T10:23:56.026484Z"
    },
    "papermill": {
     "duration": 0.146064,
     "end_time": "2022-07-11T10:23:56.029037",
     "exception": false,
     "start_time": "2022-07-11T10:23:55.882973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model_path, test_loader, num_log=1, thr=CFG.thr):\n",
    "    msks = []; imgs = [];\n",
    "    pred_strings = []; pred_ids = []; pred_classes = [];\n",
    "    for idx, (img, ids, heights, widths) in enumerate(tqdm(test_loader, total=len(test_loader), desc='Infer ')):\n",
    "        img = img.to(CFG.device, dtype=torch.float) # .squeeze(0)\n",
    "        size = img.size()\n",
    "        msk = []\n",
    "        msk = torch.zeros((size[0], 3, size[2], size[3]), device=CFG.device, dtype=torch.float32)\n",
    "        \n",
    "        model = load_model(model_path)\n",
    "        out   = model(img) # .squeeze(0) # removing batch axis\n",
    "        out   = nn.Sigmoid()(out) # removing channel axis\n",
    "        msk+=out\n",
    "        \n",
    "        msk = (msk.permute((0,2,3,1))>thr).to(torch.uint8).cpu().detach().numpy() # shape: (n, h, w, c)\n",
    "        result = masks2rles(msk, ids, heights, widths)\n",
    "        pred_strings.extend(result[0])\n",
    "        pred_ids.extend(result[1])\n",
    "        pred_classes.extend(result[2])\n",
    "        if idx<num_log:\n",
    "            img = img.permute((0,2,3,1)).cpu().detach().numpy()\n",
    "            imgs.append(img[:10])\n",
    "            msks.append(msk[:10])\n",
    "        del img, msk, out, model, result\n",
    "        torch.cuda.empty_cache()\n",
    "    return pred_strings, pred_ids, pred_classes, imgs, msks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4008947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:23:56.286627Z",
     "iopub.status.busy": "2022-07-11T10:23:56.286149Z",
     "iopub.status.idle": "2022-07-11T10:24:32.941362Z",
     "shell.execute_reply": "2022-07-11T10:24:32.940313Z"
    },
    "papermill": {
     "duration": 36.786714,
     "end_time": "2022-07-11T10:24:32.943831",
     "exception": false,
     "start_time": "2022-07-11T10:23:56.157117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Infer : 100%|██████████| 16/16 [00:36<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildDataset(test_df, transforms=data_transforms['valid'])\n",
    "test_loader  = DataLoader(test_dataset, batch_size=CFG.valid_bs, \n",
    "                          num_workers=4, shuffle=False, pin_memory=False)\n",
    "model_path=\"../input/uwmgi/last_epoch-00.bin\"\n",
    "pred_strings, pred_ids, pred_classes, imgs, msks = infer(model_path, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "501183ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-11T10:24:33.206293Z",
     "iopub.status.busy": "2022-07-11T10:24:33.205910Z",
     "iopub.status.idle": "2022-07-11T10:24:33.507978Z",
     "shell.execute_reply": "2022-07-11T10:24:33.507121Z"
    },
    "papermill": {
     "duration": 0.436054,
     "end_time": "2022-07-11T10:24:33.509950",
     "exception": false,
     "start_time": "2022-07-11T10:24:33.073896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class predicted\n",
       "0  case123_day20_slice_0001  large_bowel          \n",
       "1  case123_day20_slice_0001  small_bowel          \n",
       "2  case123_day20_slice_0001      stomach          \n",
       "3  case123_day20_slice_0002  large_bowel          \n",
       "4  case123_day20_slice_0002  small_bowel          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    \"id\":pred_ids,\n",
    "    \"class\":pred_classes,\n",
    "    \"predicted\":pred_strings\n",
    "})\n",
    "if not debug:\n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n",
    "    del sub_df['predicted']\n",
    "else:\n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n",
    "    del sub_df['segmentation']\n",
    "    \n",
    "sub_df = sub_df.merge(pred_df, on=['id','class'])\n",
    "sub_df.to_csv('submission.csv',index=False)\n",
    "display(sub_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2ec15",
   "metadata": {
    "papermill": {
     "duration": 0.129254,
     "end_time": "2022-07-11T10:24:33.769188",
     "exception": false,
     "start_time": "2022-07-11T10:24:33.639934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 314.504016,
   "end_time": "2022-07-11T10:24:37.146862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-11T10:19:22.642846",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
